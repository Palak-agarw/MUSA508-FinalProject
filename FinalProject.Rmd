---
title: "Predicting Wildfire Risk in Northern California"
author: "Leah Shapiro and Palak Agarwal"
date: "12/13/2020"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---
# Introduction
California has more wildfires than any other U.S. state. In 2020, California saw one of the worst wildfire seasons in recorded history, and climate change could lead to even more wildfire destruction in the future (Yan et al., 2020; Miller et al., 2020).

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = FALSE)

# LIBRARIES
library(rjson)
library(tidycensus)
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot)
library(jtools)  
library(viridis)
library(kableExtra)
library(rlist)
library(dplyr)
library(osmdata)
library(geosphere)
library(fastDummies)
library(FNN)
library(viridis)
library(stargazer)
library(pscl)
library(pROC)
library(plotROC)
library(RANN)
library(riem)
options(scipen=999)
options(tigris_class = "sf")

# THEMES AND FUNCTIONS
mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

# PALETTE
palette2 <- c("#F96167","#FCE77D")

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}

q5 <- function(variable) {as.factor(ntile(variable, 5))}

# FUNCTIONS
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}
```

```{r setup2, message=FALSE, warning=FALSE, cache=TRUE}
# READ IN DATA
all_counties <- st_read("C:/Users/owner160829a/Desktop/Graduate School/Penn/Courses/Fall 20/MUSA 508/Final Project/Geoprocessing/counties.shp") %>%
  st_transform('EPSG:2225')

fire_pt <- st_read("https://services1.arcgis.com/jUJYIo9tSA7EHvfZ/arcgis/rest/services/California_Fire_Perimeters/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson")%>%
  st_transform('EPSG:2225')

selected_counties <- st_read("https://opendata.arcgis.com/datasets/a61c138d0a6946da8d1ebb8d1c9db13a_0.geojson") %>%
  filter(COUNTY_NAME == 'Del Norte' | COUNTY_NAME == 'Siskiyou' | COUNTY_NAME == 'Humboldt' | COUNTY_NAME == 'Trinity' |
           COUNTY_NAME == 'Shasta' | COUNTY_NAME == 'Tehama' | COUNTY_NAME == 'Mendocino' | COUNTY_NAME == 'Glenn' |
           COUNTY_NAME == 'Lake' | COUNTY_NAME == 'Colusa' | COUNTY_NAME == 'Sonoma' |COUNTY_NAME == 'Napa' | COUNTY_NAME == 'Yolo') %>%
  st_transform('EPSG:2225')

```

```{r maps, message=FALSE, warning=FALSE}
fire_perimeter1019 <- fire_pt %>% filter(YEAR_=="2010"|YEAR_=="2011"|YEAR_=="2012"|YEAR_=="2013"|YEAR_=="2014"|YEAR_=="2015"|YEAR_=="2016"|YEAR_=="2017"|YEAR_=="2018"|YEAR_=="2019")

ggplot() +
  geom_sf(data = fire_perimeter1019, fill="orange", color="transparent")+
 geom_sf(data=all_counties, fill="transparent")+ 
  labs(title="California Wildfires",
       subtitle="Years 2010-2019")+
  mapTheme()
```

In california, homeowners in areas with high wildfire risk are required to take certain preventative measures, including clearing flammable vegetation around their home and keeping their roof clear of leaves (Public Resources Code, n.d.). Cal Fire, the state fireighting agency, is responsible for inspecting many of the state's properties for compliance with these regulations and for educating homeowners about how to mitigate their fire risk. However, due to limited funding, Cal Fire is not able to complete their inspections. In 2018, Cal Fire inspected only 17% of the properties within their jursidiction. In Northern California, which includes some of the highest risk fire areas in the state, the inspection rates are even lower (Sommer, 2019).

To support Cal Fire in their important work protecting California from fire, we have developed a mobile application called Spark Safe. Using the Spark Safe app, homeowners in 13 Northern California counties can enter their address and immediately learn their wildfire risk score. Those in high risk areas are prompted to submit an inspection through the app by taking photographs with their smart phones and completing a basic form. All users will also have access to educational content about wildfire prevention and safety through the app. Spark Safe will enable Cal Fire to dramatically expand their reach and help to improve wildfire prevention compliance throughout the 13 counties. The following counties are included in the app due to having both high wildfire risk and low Cal Fire inspection rates:

+ Colusa
+ Del Norte
+ Glenn
+ Humboldt
+ Lake
+ Mendocino
+ Napa
+ Shasta
+ Siskiyou
+ Sonoma
+ Tehama
+ Trinity
+ Yolo

```{r maps2, message=FALSE, warning=FALSE}
## Showing our selected counties
ggplot() +
  geom_sf(data = fire_perimeter1019, fill="orange", color="transparent")+
  geom_sf(data=all_counties, fill="transparent", size=.5, color="grey")+ 
  geom_sf(data=selected_counties, fill="transparent", color="#F96167", size=1)+
  labs(title="California Wildfires",
       subtitle="Years 2010-2019; Selected Counties in Red")+
  mapTheme()
```

Spark Safe's wildfire risk score is based on the probability of a wildfire occuring in a given area as predicted by a logistic regression. This document outlines how Spark Safe's data scientists developed that logistic regression. In sharing this, we hope to inspire other agencies to open the "black box" of algorithmic governance and to increase transparency in the algorithms used to inform public policy decisions.

Follow this link to view a short video about the Spark Safe app: INSERT YOUTUBE LINK HERE

# Data
The following datasets were used to develop the logistic model. All data is from publically available sources.

+ Fire perimeters in California dating from 1878 - 2019. These records are complete from 2002 to present.  
+ Aspects of the wildlife urban interface (WUI): interface, intermix, influence zone, and not WUI
+ Vegetation types
+ Elevation
+ Land Cover
+ County borders
+ Weather, including temperature, precipitation, humidity, wind speed

## ArcMap Processing
Many of the datasets were available in raster form. Because R does not support raster well, we did our initial data wrangling in ArcMap. First, we created a .5 x.5 mile fishnet for the entire state. WHY DID WE CHOOSE THIS SIZE?

(create_fishnet3.jpg)

Next, files were reclassified if necesssary to ensure that the appropriate values would be used by the zonal statistics as a table tool. 

(reclassify.jpg)

We then calculated slope from the elevation data using the slope spatial analyst tool.

(slope.jpg)

Using the zonal statistics as a table tool, we determined the majority value for each dataset represented in each fishnet gridcell. For slope and elevation, the mean was calculated rather than the majority.

(zonal.jpg)

We then joined each zonal statistics table to our fishnet based on the unique ID number of the fishnet grid cells. The final fishnet was exported as a shapefile, read into R, and clipped to our 13 selected counties.

(join.jpg)


```{r data, message=FALSE, warning=FALSE, cache=TRUE}
## READ IN DATA
fire_suppression_facilities <- st_read("C:/Users/owner160829a/Desktop/Graduate School/Penn/Courses/Fall 20/MUSA 508/Final Project/Geoprocessing/fire_suppression_facilities.shp")

fishnet_unclipped <- st_read("C:/Users/owner160829a/Desktop/Graduate School/Penn/Courses/Fall 20/MUSA 508/Final Project/Geoprocessing/Fishnet with Joined Data/fishnet_halfmile_joins.shp") %>%
  st_transform('EPSG:2225')

fishnet_clipped <- st_intersection(fishnet_unclipped,selected_counties)

fishnet_clipped <- fishnet_clipped %>% dplyr::select(WUI_MAJORI,FVEG_MAJOR,ELEVATION_,SLOPE_MEAN,COVER_MAJ, COUNTY_NAME, geometry) %>%
  rename (WUI_MAJ=WUI_MAJORI, 
          FVEG_MAJ=FVEG_MAJOR,
          ELEVATION_AV=ELEVATION_)

# Adding Unique IDs for each cell, these were lost when exporting from ArcMap
fishnet_clipped$ID <-  seq.int(nrow(fishnet_clipped))
```


```{r fire_data, message=FALSE, warning=FALSE, cache=TRUE}
## Joining fire data to fishnets 
###2014-18
fire_perimeter1418 <-
  fire_pt %>%
  filter(YEAR_  == '2014' | YEAR_  == '2015' | YEAR_  == '2016' | YEAR_ =='2017' | YEAR_  == '2018') %>%
  st_transform('EPSG:2225')

clip1418 <- 
  st_intersection(st_make_valid(fire_perimeter1418),st_make_valid(fishnet_clipped)) %>%
  select(ID) %>%
  st_drop_geometry() %>%
  mutate(Fire1418 = 1) %>%
  distinct()

fishnet_clipped <-
  fishnet_clipped %>%
  left_join(., clip1418, on= 'ID') 

fishnet_clipped$Fire1418 <- ifelse(is.na(fishnet_clipped$Fire1418),0, fishnet_clipped$Fire1418)

###2019
fire_perimeter19 <-
  fire_pt %>%
  filter(YEAR_ =='2019') %>%
  st_transform('EPSG:2225')

clip19 <- 
  st_intersection(st_make_valid(fire_perimeter19),st_make_valid(fishnet_clipped)) %>%
  select(ID) %>%
  st_drop_geometry() %>%
  mutate(Fire19 = 1) %>%
  distinct()

fishnet_clipped <-
  fishnet_clipped %>%
  left_join(., clip19, on= 'ID') 

fishnet_clipped$Fire19 <- ifelse(is.na(fishnet_clipped$Fire19),0, fishnet_clipped$Fire19)
```

## Weather Data Processing
Using the riem package in R, we identified weather stations that were in and around our selected counties. We then associated each of these stations with our fishnet using the nearest neighbor function and retrieved weather data from each station for fire season months (July to October) for our years of interest.

```{r weather_data, message=FALSE, warning=FALSE, cache=TRUE}
## WEATHER DATA

# vector 1 - of southern california station ids
weather_station_ids <- c("SIY", "CEC", "MHS", "O86", "ACV", "FOT", "RDD", "RBL", "CIC", "OVE",
                         "UKI", "MYV", "STS", "O69", "DVO", "APC", "SUU", "VCB", "EDU", "SMF", "LHM", "MYV")

# df - stations with lat/lon and name info (in addition to ids)
asos_socal_stations <- riem_stations("CA_ASOS") %>% filter(str_detect(id, paste(weather_station_ids, collapse="|")))
asos_socal_stations$weather_station_id <- asos_socal_stations$id
asos_socal_stations <-  st_as_sf(asos_socal_stations, coords = c("lon","lat"), crs = 4326, agr = "constant") %>% st_transform('EPSG:2225')
asos_socal_stations$weather_ID <-  seq.int(nrow(asos_socal_stations))

## Finding closest station
weather_coords <- 
  asos_socal_stations %>%
  select(geometry)

fishnet_coords <- 
  fishnet_clipped %>%
  select(geometry)

closest_weather_station_to_fishnet <- nn2(weather_coords, fishnet_coords, k = 1)$nn.idx

fishnet_clipped$weather_ID <- closest_weather_station_to_fishnet

#ggplot()+
 # geom_sf(data = selected_counties)+
  #geom_sf(data = weather_coords)

# function and loop -- tried it with the vector of ids and the df of all info, but neither worked. This version below uses just the vector of station ids
get_weather_features_by_station <- function(weather_station_ids, start_year, end_year){
  
  year_vec <- seq(start_year, end_year)
  i <- 1
  weather_data_list <- list()
  for(station_id in weather_station_ids){
    print(paste("Processing station", station_id))
    for(year in year_vec){
      start_date = paste0(year, "07-01")
      end_date = paste0(year, "10-31")
      weather_data <- riem_measures(station = station_id, date_start = start_date, date_end = end_date) %>% 
        dplyr::summarise(weather_station_id = station_id,
                         year = year,
                         Max_Temp = max(tmpf, na.rm = TRUE),
                         Mean_Temp = mean(tmpf, na.rm = TRUE),
                         Mean_Precipitation = mean(p01i, na.rm = TRUE),
                         Mean_Humidity = mean(relh, na.rm = TRUE),
                         Mean_Wind_Speed = mean(sknt, na.rm = TRUE),
        ) 
      weather_data_list[[i]] <- weather_data
      i <- i + 1
    }
  }
  
  do.call("rbind", weather_data_list) 
}

weather_data2014 <- get_weather_features_by_station(weather_station_ids, 2014, 2014) %>%
  rename(Max_Temp14 = Max_Temp,
         Mean_Temp14 = Mean_Temp,
         Mean_Precipitation14 = Mean_Precipitation,
         Mean_Humidity14 = Mean_Humidity,
         Mean_Wind_Speed14 = Mean_Wind_Speed)

weather_2014 <- left_join(weather_data2014, asos_socal_stations, on = 'weather_station_id') %>%
  select (-weather_station_id, -id, -name, -year, -geometry) %>%
  distinct() 

fishnet_clipped <- left_join(fishnet_clipped, weather_2014, on = "weather_ID")

weather_data2015 <- get_weather_features_by_station(weather_station_ids, 2015, 2015) %>%
  rename(Max_Temp15 = Max_Temp,
         Mean_Temp15 = Mean_Temp,
         Mean_Precipitation15 = Mean_Precipitation,
         Mean_Humidity15 = Mean_Humidity,
         Mean_Wind_Speed15 = Mean_Wind_Speed)

weather_2015 <- left_join(weather_data2015, asos_socal_stations, on = 'weather_station_id') %>%
  select (-weather_station_id, -id, -name, -year, -geometry) %>%
  distinct()

fishnet_clipped <- left_join(fishnet_clipped, weather_2015, on = "weather_ID")

weather_data2016 <- get_weather_features_by_station(weather_station_ids, 2016, 2016) %>%
  rename(Max_Temp16 = Max_Temp,
         Mean_Temp16 = Mean_Temp,
         Mean_Precipitation16 = Mean_Precipitation,
         Mean_Humidity16 = Mean_Humidity,
         Mean_Wind_Speed16 = Mean_Wind_Speed)

weather_2016 <- left_join(weather_data2016, asos_socal_stations, on = 'weather_station_id') %>%
  select (-weather_station_id, -id, -name, -year, -geometry)%>%
  distinct() 

fishnet_clipped <- left_join(fishnet_clipped, weather_2016, on = "weather_ID")

weather_data2017 <- get_weather_features_by_station(weather_station_ids, 2017, 2017) %>%
  rename(Max_Temp17 = Max_Temp,
         Mean_Temp17 = Mean_Temp,
         Mean_Precipitation17 = Mean_Precipitation,
         Mean_Humidity17 = Mean_Humidity,
         Mean_Wind_Speed17 = Mean_Wind_Speed)

weather_2017 <- left_join(weather_data2017, asos_socal_stations, on = 'weather_station_id') %>%
  select (-weather_station_id, -id, -name, -year, -geometry)%>%
  distinct() 

fishnet_clipped <- left_join(fishnet_clipped, weather_2017, on = "weather_ID")

weather_data2018 <- get_weather_features_by_station(weather_station_ids, 2018, 2018) %>%
  rename(Max_Temp18 = Max_Temp,
         Mean_Temp18 = Mean_Temp,
         Mean_Precipitation18 = Mean_Precipitation,
         Mean_Humidity18 = Mean_Humidity,
         Mean_Wind_Speed18 = Mean_Wind_Speed)

weather_2018 <- left_join(weather_data2018, asos_socal_stations, on = 'weather_station_id') %>%
  select (-weather_station_id, -id, -name, -year, -geometry)%>%
  distinct() 

fishnet_clipped <- left_join(fishnet_clipped, weather_2018, on = "weather_ID")

weather_data2019 <- get_weather_features_by_station(weather_station_ids, 2019, 2019) %>%
  rename(Max_Temp19 = Max_Temp,
         Mean_Temp19 = Mean_Temp,
         Mean_Precipitation19 = Mean_Precipitation,
         Mean_Humidity19 = Mean_Humidity,
         Mean_Wind_Speed19 = Mean_Wind_Speed)

weather_2019 <- left_join(weather_data2019, asos_socal_stations, on = 'weather_station_id') %>%
  select (-weather_station_id, -id, -name, -year, -geometry)%>%
  distinct() 

fishnet_clipped <- left_join(fishnet_clipped, weather_2019, on = "weather_ID")
```

## Feature Engineering

After wrangling all of our data, we engineered the following new features to test in our model:
+ A binary variable indicating whether or not a fire occured in each grid cell from 2010-2013
+ A continuous variable of the number of historical fires in each grid cell
+ Categorical variables for land cover type and slope
+ A binary variable indicating whether the mean elevation is greater than 3000 feet.
+ Continuous variables representing the distance to the nearest grid cells primarily composed of conifer, shrub, and hardwood respectively
+ A continuous variable representing distance to the wildlife urban interface
+ A continuous variable
+ A continuous variable representing the distance to the nearest 3 fire suppression facilities
+ A continuous variable representing the distance to the nearest 10 grid cells with fires in 2010-2013

```{r features, message=FALSE, warning=FALSE}
# FEATURE ENGINEERING
# Finding Means of Weather data
fishnet_clipped$MeanTemp1418 = (fishnet_clipped$Mean_Temp14+
                                  fishnet_clipped$Mean_Temp15+
                                  fishnet_clipped$Mean_Temp16+
                                  fishnet_clipped$Mean_Temp17+
                                  fishnet_clipped$Mean_Temp18)/5

fishnet_clipped$MeanHumidity1418 = (fishnet_clipped$Mean_Humidity14+
                                      fishnet_clipped$Mean_Humidity15+
                                      fishnet_clipped$Mean_Humidity16+
                                      fishnet_clipped$Mean_Humidity17+
                                      fishnet_clipped$Mean_Humidity18)/5

fishnet_clipped$MeanPrecip1418 = (fishnet_clipped$Mean_Precipitation14+
                                    fishnet_clipped$Mean_Precipitation15+
                                    fishnet_clipped$Mean_Precipitation16+
                                    fishnet_clipped$Mean_Precipitation17+
                                    fishnet_clipped$Mean_Precipitation18)/5

fishnet_clipped$MeanWindSpeed1418 = (fishnet_clipped$Mean_Wind_Speed14+
                                       fishnet_clipped$Mean_Wind_Speed15+
                                       fishnet_clipped$Mean_Wind_Speed16+
                                       fishnet_clipped$Mean_Wind_Speed17+
                                       fishnet_clipped$Mean_Wind_Speed18)/5

fishnet_clipped$MeanMaxTemp = (fishnet_clipped$Max_Temp14+
                                 fishnet_clipped$Max_Temp15+
                                 fishnet_clipped$Max_Temp16+
                                 fishnet_clipped$Max_Temp17+
                                 fishnet_clipped$Max_Temp18)/5

# Remove Unnecessary Variables
fishnet_clipped <- fishnet_clipped %>% dplyr::select (                                                -Mean_Temp14,-Mean_Temp15,-Mean_Temp16,-Mean_Temp17,                                                -Mean_Temp18,-Mean_Humidity14,-Mean_Humidity15,
                                                      -Mean_Humidity16,-Mean_Humidity17,-Mean_Humidity18,
                                                      -Mean_Precipitation14,-Mean_Precipitation15,                                   -Mean_Precipitation16, -Mean_Precipitation17,
                                                      -Mean_Precipitation18,-Mean_Wind_Speed14,
                                                      -Mean_Wind_Speed15,-Mean_Wind_Speed16,
                                                      -Mean_Wind_Speed17,-Mean_Wind_Speed18,
                                                      -Max_Temp14,-Max_Temp15,-Max_Temp16,-Max_Temp17,-Max_Temp18)

## Changing Integers to Characters

fishnet_clipped$WUI_MAJ <- as.factor(fishnet_clipped$WUI_MAJ)

fishnet_clipped$FVEG_MAJ <- as.factor(fishnet_clipped$FVEG_MAJ)

fishnet_clipped$COVER_MAJ <- as.factor(fishnet_clipped$COVER_MAJ)

## Fire in last 3 years
fire_perimeter1013 <-
  fire_pt %>%
  filter(YEAR_  == '2010' | YEAR_ =='2011'| YEAR_ =='2012'| YEAR_ =='2013') %>%
  st_transform('EPSG:2225')

clip1013 <- 
  st_intersection(st_make_valid(fire_perimeter1013),st_make_valid(fishnet_clipped)) %>%
  select(ID) %>%
  st_drop_geometry() %>%
  mutate(Fire1013 = 1) %>%
  distinct()

fishnet_clipped <-
  fishnet_clipped %>%
  left_join(., clip1013, on= 'ID') 

fishnet_clipped$Fire1013 <- ifelse(is.na(fishnet_clipped$Fire1013),0, fishnet_clipped$Fire1013)

## Historical fire
##intersections of fire perimeters with each fishnet cell.
fishnet_clipped <- 
  fishnet_clipped %>% 
  mutate(n_fires_intersections = lengths(st_intersects(st_make_valid(fishnet_clipped), st_make_valid(fire_pt))))

## adding a column for y/n for historical fire presence
#fishnet_clipped <-
 # fishnet_clipped %>%
  #mutate(prev_fire = ifelse(fishnet_clipped$n_fires_intersections > 0, "1", "0"))

## Categorical Features
fishnet_clipped <- fishnet_clipped %>% mutate(CoverCat = case_when(fishnet_clipped$COVER_MAJ=="1"|fishnet_clipped$COVER_MAJ=="2"|fishnet_clipped$COVER_MAJ=="4" ~ "forest",
                                              fishnet_clipped$COVER_MAJ=="6"|fishnet_clipped$COVER_MAJ=="7" ~ "shrubland",
                                              fishnet_clipped$COVER_MAJ=="8"|fishnet_clipped$COVER_MAJ=="9"|fishnet_clipped$COVER_MAJ=="10"~ "savanna_grassland",
                                              fishnet_clipped$COVER_MAJ=="11"|fishnet_clipped$COVER_MAJ=="15"|fishnet_clipped$COVER_MAJ=="17"~ "wet",
                                              fishnet_clipped$COVER_MAJ=="14"|fishnet_clipped$COVER_MAJ=="12" ~ "cropland",
                                              fishnet_clipped$COVER_MAJ=="13" ~ "urban",
                                              fishnet_clipped$COVER_MAJ=="17" ~ "barren"))


fishnet_clipped <- fishnet_clipped %>% mutate(SlopeCat = case_when(fishnet_clipped$SLOPE_MEAN < 5 ~ "low",
                                                                   fishnet_clipped$SLOPE_MEAN >=5 & fishnet_clipped$SLOPE_MEAN <15 ~ "medium",
                                                                   fishnet_clipped$SLOPE_MEAN >=15 ~ "high" ))

## Replacing Land Cover type 15 (perm snow and ice) with type 17 (waterbodies)
fishnet_clipped$COVER_MAJ <- ifelse(fishnet_clipped$COVER_MAJ=="15","17",fishnet_clipped$COVER_MAJ)

## Dummy Feature
fishnet_clipped <- fishnet_clipped %>% mutate (ElevationBi = if_else(fishnet_clipped$ELEVATION_AV>3000,1,0))

## Nearest Neighbor Features
conifer_points <- fishnet_clipped %>% filter(FVEG_MAJ=="1") %>% st_centroid()

shrub_points<- fishnet_clipped %>% filter(FVEG_MAJ=="2") %>% st_centroid()

hardwood_points <- fishnet_clipped %>% filter(FVEG_MAJ=="6") %>% st_centroid()

wui_points <- fishnet_clipped %>% filter(WUI_MAJ=="4") %>% st_centroid()

fire1013_points <- fishnet_clipped %>% filter(Fire1013=="1") %>% st_centroid()

fishnet_clipped <- fishnet_clipped %>%
  mutate(
    Conifer.nn =
      nn_function(st_coordinates(st_centroid(fishnet_clipped)), st_coordinates(conifer_points),1),
    Shrub.nn=
      nn_function(st_coordinates(st_centroid(fishnet_clipped)), st_coordinates(shrub_points),1),
    Hardwood.nn=
      nn_function(st_coordinates(st_centroid(fishnet_clipped)), st_coordinates(hardwood_points),1),
    Facilities.nn=
      nn_function(st_coordinates(st_centroid(fishnet_clipped)), st_coordinates(fire_suppression_facilities),3),
    WUI.nn=
      nn_function(st_coordinates(st_centroid(fishnet_clipped)), st_coordinates(wui_points),1),
    Fire.nn=
      nn_function(st_coordinates(st_centroid(fishnet_clipped)), st_coordinates(fire1013_points),10))

```

## Exploratory Analysis
The bar plots below visualize the continuous variables that were considered for the logistic model. The y-axis shows the mean value of each variable for grid cells that did have fires in 2014-2018 and those that did not have fires. Variables that show significant differences between grid cells that do and do not have fire are likely be useful for the model.

The bar plots illustrate the following:
+ The mean distance to conifer, hardwood, and shrub is smaller for cells that had fires
+ The mean elevation and mean slope is higher for cells that had fires
+ The mean number of historical fires is higher for cells that had fires
+ The mean distance to the wildlife urban interface is smaller for cells that had fires
+ There is not a noticeable difference in mean humidity, maximum temperature, preciptation, or wind speed for cells that had fires. However, several of these features did end up improving the model.
+ There is not a noticeable difference in distance to 3 nearest fire suppression facilities for cells that had fires versus cells that did not.

```{r exploratory, message=FALSE, warning=FALSE}
# DATA VISUALIZATIONS
##continuous variables
### Need to fix legend here
fishnet_clipped$FIRE <- ifelse(fishnet_clipped$Fire1418==1,"Fire","No_Fire")

fishnet_clipped %>% st_drop_geometry() %>%
  dplyr::select(FIRE, ELEVATION_AV, SLOPE_MEAN,MeanMaxTemp, MeanTemp1418,MeanHumidity1418,
                MeanPrecip1418,MeanWindSpeed1418, n_fires_intersections, Conifer.nn, Shrub.nn, Hardwood.nn, 
                Facilities.nn, WUI.nn) %>%
  rename("Elevation" = ELEVATION_AV, "Slope" = SLOPE_MEAN) %>%
  gather(Variable, value, -FIRE) %>%
  ggplot(aes(FIRE, value, fill=FIRE)) + 
  geom_bar(position = "dodge", stat = "summary", fun = "mean") + 
  facet_wrap(~Variable, scales = "free") +
  scale_fill_manual(values = palette2) +
  labs(x="Fire", y="Mean", 
       title = "Feature associations with the likelihood of Wildfire",
       subtitle = "(continous outcomes)") +
  theme(legend.position = "none")
```

Colinearity can undermine the interpretability of a model. To help us avoid colinearity, we visualized correlations among our continuous variables. Unsurprisingly, mean temperature and mean maximum temperature are highly positively correlated. The correlation matrix also shows that temperature is negatively correlated with humidity.

```{r colinear, message=FALSE, warning=FALSE}
# Identifying Colinearity 
numericVars <- select_if(fishnet_clipped, is.numeric) %>% na.omit() %>% st_drop_geometry() %>%
  dplyr::select(ELEVATION_AV,SLOPE_MEAN,MeanTemp1418,MeanHumidity1418,
                MeanPrecip1418,MeanWindSpeed1418,MeanMaxTemp, n_fires_intersections,Conifer.nn, Shrub.nn, Hardwood.nn, 
                Facilities.nn, WUI.nn)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
  labs(title = "Correlation across Characteristics") 
```

The maps below visualize categorical variables and fire in the 13 counties under analysis. The maps suggest the following:
+ Most fires seem to occur outside of the wildlife urban interface.
+ Fires seem especially prevelant in areas dominated by conifer vegetation 
+ Fires seem especially prevelatn in savannas
 
```{r exploratory_maps, message=FALSE, warning=FALSE, cache=TRUE}
Fire1418DF <- st_intersection(st_make_valid(fire_perimeter1418),st_make_valid(selected_counties))

palette5 <- c("#edf8e9", "#bae4b3", "#74c476", "#31a354", "#006d2c")

palette9 <- c("#f7fcf5", "#e5f5e0", "#c7e9c0", "#a1d99b", "#74c476", "#41ab5d", "#238b45", "#006d2c", "#00441b")

palatte_nlcd <- c("#aec3d4", "#33510d", "#e2720f", "#369b47", "#30eb5b", "#387242", "#ff6100", "#c3aa69", "#b76031", "#d9903d",

                  "#a9c952", "#111149", "#cdb33b", "#c40f5a", "#33280d", "#2784A7")

 

ggplot() +

  geom_sf(data = fishnet_clipped, aes(fill = WUI_MAJ), color = "transparent")+

  geom_sf(data = Fire1418DF, fill = "transparent", color = "red", size = 0.5)+

  scale_fill_manual(values = palette5, name="WUI Type", labels=c("Missing Data","Not WUI","Influence Zone","Intermix","Interface")) +

  labs(title="Wildlife Urban Interface and Fire",
       subtitle = "Red outline denotes fire perimeters 2014-2018") +

  mapTheme()

 

ggplot() +

  geom_sf(data = fishnet_clipped, aes(fill = FVEG_MAJ), color = "transparent")+

  geom_sf(data = Fire1418DF, fill = "transparent", color = "red", size = 0.5)+

  scale_fill_manual(values = palette9, name="Vegetation Type", labels=c("Missing Data","Conifer","Shrub","Herbaceous","Barren", "Urban", "Hardwood", "Water",      "Agriculture")) +

  labs(title="Vegetation Cover and Fire",
       subtitle = "Red outline denotes fire perimeters 2014-2018") +

  mapTheme()

 

ggplot() +
geom_sf(data = fishnet_clipped, aes(fill = COVER_MAJ), color = "transparent") +
geom_sf(data = Fire1418DF, fill = "transparent", color = "red", size = 0.5) +
scale_fill_manual(values = palatte_nlcd, name="Land Cover Type", labels=c("Evergreen Needleleaf", "Evergreen Broadleaf", "Deciduous Needleleaf", "Deciduous Broadleaf", "Mixed Forests", "Closed Shrublands", "Open Shrubland", "Woody Savannas", "Savannas", "Grassland", "Permanent Wetland", "Cropland", "Urban and Built-up Lands", "Cropland/Natural Vegetation Mosaics", "Permanent Snow and Ice", "Water Bodies")) +
labs(title="National Land Cover \nData and Fire",
       subtitle = "Red outline denotes \nfire perimeters \n2014-2018") +
 mapTheme()
 


  

```

## Describe the Spatial Process/ Space Time Process
NOT SURE WHAT TO PUT HERE. Did we already cover this above?

# Model
Rare events are difficult to model, and attempts to do so often lead to underprediction. In our first attempts at building a logistic regression, we developed models with very high accuracy rates. However, these models predicted almost no fires. We initially trained our model on 2016-2018 fire perimeter data, but decided to include 2014 and 2015 data to combat the rare event problem. We also added 3 counties to the original 10 counties that we analyzed to increase the occurance of fire in our dataset.

In choosing a final model, we aimed for statistically significant independent variables, a relatively high McFadden pseudo R squared, and a large area under the receiver operating curve. We also evaluated confusion metrics. Given our use case, we felt that increasing the number of true positives was more important than maximizing true negatives or minimizing false positives. Therefore, we intentionally created a model that overpredicts for wildfire.

The final model includes the following features:
+ FVEG_MAJ (vegetation type that makes up the majority of the grid cell)
+ ELEVATION_AV (average elevation in the grid cell)
+ SLOPE_MEAN (average slope in the grid cell)
+ COVER_MAJ (majority land cover type in grid cell)
+ COUNTY_ NAME 
+ MeanTemp1418 (mean temperature during the fire season from 2014-2018)
+ MeanHumidity1418 (mean humidity during the fire season from 2014-2018)
+ MeanWindSpeed1418 (mean wind speed during the fire season from 2014-2018)
+ n_fires_intersections (number of fires occurring in that grid cell)
+ Conifer.nn (distance to nearest grid cell that is majority conifer)
+ Hardwood.nn (distance to nearest grid cell that is majority hardwood)
+ Facilities.nn (distance to 5 nearest fire suppression facilities)

The output below demonstrates that these features are highly statistically significant.

```{r model, message=FALSE, warning=FALSE}
# LOGISTIC MODEL
set.seed(1214)
trainIndex <- createDataPartition(fishnet_clipped$Fire1418, p = .65, 
                                 y = paste(fishnet_clipped$COVER_MAJ),
                                  list = FALSE,
                                  times = 1)

fireTrain <- fishnet_clipped[ trainIndex,] %>% st_drop_geometry()
fireTest  <- fishnet_clipped[-trainIndex,] %>% st_drop_geometry()

# MODEL
fireModel <- glm(Fire1418 ~ .,
                    data=fireTrain %>% 
                      dplyr::select(-ID,-Fire19,-weather_ID, -WUI_MAJ, -WUI.nn, 
                                    -MeanMaxTemp,-FIRE, -CoverCat, -ElevationBi,
                                    -Fire.nn, -SlopeCat, -MeanPrecip1418, -Max_Temp19, 
                                    -Mean_Temp19, -Mean_Precipitation19, 
                                    -Mean_Humidity19, -Mean_Wind_Speed19, -Fire1013, -Shrub.nn),
                    family="binomial" (link="logit"))

summary(fireModel)

## Adding Coefficients
x <- fireModel$coefficients
exp(x)
```


## Goodness of Fit
### Pseudo R Squared
The McFadden pseudo r squared for this model is about .39. While this number is not particularly meaningful on its in, the McFadden pseudo r squared results for different iterations of the model were compared. A higher McFadden pseudo r squared indicates better accuracy. 

```{r mcfadden, message=FALSE, warning=FALSE}
## Fit metrics
pR2(fireModel)
```

### ROC Curve
The logistic model predicts the probability of fire occuring in a given .25 square mile grid cell from 0 to 1. To validate our model, we chose a probability threshold above which fire is predicted to occur. 

The receiver operating characteristic (ROC) curve visualizes trade-offs for different thresholds for the feature engineered model. As true positives in the model increase, the number of false positives also increase. For the Spark Safe app, we are more interested in increasing the true positive rate than in decreasing the false positive rate. However, if the false positive rate is too high, homeowners may not take the app's predictions seriously. This could lead to a decrease in compliance with wildfire prevention measures in high fire risk areas.

An area under the curve (AUC) of .5 would be a coin toss, meaning the true positive rate and false positive rate are equal. An AUC of 100% would be a perfect fit with 100% true negatives and 0 false positives. Here, we have an AUC of about .92, which indicates that the model has a high goodness of fit.

```{r roc, message=FALSE, warning=FALSE}

## Prediction
testProbs <- data.frame(Outcome = as.factor(fireTest$Fire1418),
                        Probs = predict(fireModel, fireTest, type= "response"))

# ROC Curve
## This us a goodness of fit measure, 1 would be a perfect fit, .5 is a coin toss
auc(testProbs$Outcome, testProbs$Probs)

ggplot(testProbs, aes(d = as.numeric(testProbs$Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Model with Feature Engineering")
```
### Distribution of Predicted Probabilities
The plots below show the distribution of predicted probabilities for fire and no fire. The predicted probabilities for no fire cluster around 0. However, the predicted probabilities for areas that do have fire do not cluster around 1. This is because wildfire is a relatively rare event, so very few grid cells have a high probability of wildfire. Although we used 5 years of fire data, only 16% of our fishnet grid cells had wildfires during the time period under analysis. 

given the distribution ofpredicted probabilities for grid cells that have fires, the default threshold of .5 does not make sense. For our use case, we would prefer to over predict fires than to underpredict. 

```{r fit, message=FALSE, warning=FALSE}

#Here we want more of a hump in the bottom plot around 1 to indicate that the reg is predictive
ggplot(testProbs, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Fire", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome",
       subtitle = "First Model") +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "none")

# Histograms
testProbsFire <- testProbs %>% filter (Outcome=="1")
testProbsNoFire <- testProbs %>% filter (Outcome=="0")

hist(testProbsFire$Probs, 
     col="#F96167",
       main="Predicted Probabilities for Grid Cells with Fire",
     xlab="Probability")

hist(testProbsNoFire$Probs, 
     col="#FCE77D",
       main="Predicted Probabilities for Grid Cells with No Fire",
     xlab="Probability")
```

###Confusion Matrix 
Finally, we generated a confusion matrix for each iteration of our model.The confusion matrix tells us the number of true positives, true negatives, false positives, and false negatives for the model. A true positive here indicates that at a given threshold, the model correctly predicted that a wildfire would occur in a given .5 x .5 mile grid cell. A true negative means that our model correctly predicted that a wildfire would not occur. False positive means the model predicted fire, but no fire occured. False negative indicates that the model predicted no fire, but there was fire. The confusion matrix output also shows the sensitivity, or true positive rate, and specificity, or true negative rate, for the model.

Given the distribution of predicted probabilities and our desire to overpredict rather than underpredict wildfire, we used a threshold of just .2 when comparing models.The final model has a sensitivity of about 80%.

```{r matrix, message=FALSE, warning=FALSE}
## Confusion matrix
testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$Probs > 0.2 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "1")
```

#Validating the Model 
##Choosing a Threshold
A cost benefit analysis is often used to determine the appropriate threshold for a logistic regression. In this case, a monetary cost benefit analysis does not make sense, given that the cost of adhering to fire prevention regulations is significantly lower than the cost of rebuilding a home. There are no monetary gains for homeowners in our use case, only monetary losses of different degrees.

To choose a threshold, we replaced the 2014-2018 weather data with 2019 weather data in our model and generated probability predictions. We then visualized the distribution of predicted probabilities for cells with and without fire in 2019 and calculated the mean predicted probability for both cases. The mean predicted probability for cells with no fire is 0.006. The mean predicted probability for cells with fire is .248. This led us to choose a threshold of .2.

The confusion matrix below shows that our sensitivity is poor when predicting on 2019 data. This may be because our model is overfit on the training dataset and not generalizable to future years. The generalizability of the model will need to be improved before the Spark Safe app is ready for public use.

```{r 2019, message=FALSE, warning=FA:SE}
fireModel19 <- glm(Fire19 ~ .,
                 data=fishnet_clipped %>% st_drop_geometry()%>%
                   dplyr::select(-ID,-weather_ID, -Fire1418, -WUI_MAJ, -WUI.nn, 
                                 -MeanMaxTemp,-FIRE, -CoverCat, -ElevationBi,
                                 -Fire.nn, -SlopeCat, -MeanPrecip1418, -MeanMaxTemp, 
                                 -MeanTemp1418, -Mean_Precipitation19, 
                                 -MeanHumidity1418, -MeanWindSpeed1418, -Fire1013, -Shrub.nn),
                 family="binomial" (link="logit"))

summary(fireModel19)

testProbs19 <- data.frame(Outcome = as.factor(fishnet_clipped$Fire19),
                        Probs = predict(fireModel19, fishnet_clipped, type= "response"))

testProbs19nofire <- testProbs19 %>% filter(Outcome==0)
testProbs19fire <- testProbs19 %>% filter (Outcome==1)

hist(testProbs19nofire$Probs)
hist(testProbs19fire$Probs)

##0.006063904
mean(testProbs19nofire$Probs)

#0.2477918
mean(testProbs19fire$Probs)

## Confusion Matrix for 2019 at .20 threshold
testProbs19 <- 
  testProbs19 %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs19$Probs > 0.20 , 1, 0)))

caret::confusionMatrix(testProbs19$predOutcome, testProbs19$Outcome, 
                       positive = "1")
```

The graph below visualizes confusion metrics for every possible threshold from 0 to 1. At .2, the true positive rate is high and the false negative rate is relatively low. A lower threshold would increase the true positive rate and decrease the false negative rate, but the false positive rate would also increase. This could lead to distrust in the application's predictions, which may reduce compliance. Therefore, our app will rate houses located in grid cells with .2 predicted probability or above as high risk zones, while houses with predicted probabilities greater than 0 but less than .2 will be deemed medium risk zones.

ADD BLACK LINE HERE AT .2
```{r threshold, warning=FALSE, message=FALSE}
iterateThresholds <- function(data, observedClass, predictedProbs, group) {
#This function takes as its inputs, a data frame with an observed binomial class (1 or 0); a vector of predicted probabilities; and optionally a group indicator like race. It returns accuracy plus counts and rates of confusion matrix outcomes. It's a bit verbose because of the if (missing(group)). I don't know another way to make an optional parameter.
  observedClass <- enquo(observedClass)
  predictedProbs <- enquo(predictedProbs)
  group <- enquo(group)
  x = .01
  all_prediction <- data.frame()
  
  if (missing(group)) {
  
    while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x,2))
    
    all_prediction <- rbind(all_prediction,this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
  else if (!missing(group)) { 
   while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      group_by(!!group) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x,2))
    
    all_prediction <- rbind(all_prediction,this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
}

whichThreshold <- 
  iterateThresholds(
     data=testProbs, observedClass = Outcome, predictedProbs = Probs)

whichThreshold <- 
  whichThreshold %>%
    dplyr::select(starts_with("Rate"), Threshold) %>%
    gather(Variable, Rate, Rate_TN,Rate_TP,Rate_FN,Rate_FP) 

ggplot(data=whichThreshold, aes(Threshold,Rate,color=Variable)) +
  geom_point()
  
whichThreshold %>%
  ggplot(.,aes(Threshold,Rate,colour = Variable)) +
  geom_point() +
  #scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Revenue by confusion matrix type and threshold",
       y = "Count") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 

```

## Cross Validation
Although our  model did not predict well on 2019 data, we performed other validation tests to judge the generalizability of our model. First, cross validation with 100 k folds was performed. The graphs below visualize teh area under the ROC curve, sensitivity, and specificity o fthe final model across folds. Each of these plots are clustered around the mean, indicating our model has decent generalizability. However, the generalizability of the model's sensitivity could be improved.

The first outputs indicate the area under the Receiver Operating Characteristic (ROC) curve, the sensitivity, and the specificity for the model. Again we see that both models have high specificity (true negative rates), but low sensitivity. The second output visualizes these metrics for both models across folds. If the models were generalizable, we wouldexpect all of these plots to be clustered around the mean. 

MAKE SURE THIS MATCHES FINAL MODEL
```{r cv, message=FALSE, warning=FALSE, cache=TRUE}
# K Fold Model Validation
ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

cvFit <- train(Fire1418 ~ ., data = fishnet_clipped %>% st_drop_geometry() %>%
                 dplyr::select(
                   -ID,-Fire19,-weather_ID, -WUI_MAJ,
                   -MeanMaxTemp,-FIRE, -CoverCat, -ElevationBi,
                   -Fire.nn, -SlopeCat, -MeanPrecip1418, -Max_Temp19, 
                   -Mean_Temp19, -Mean_Precipitation19, 
                   -Mean_Humidity19, -Mean_Wind_Speed19, -Fire1013, -Shrub.nn)%>%
                 dplyr::mutate(Fire1418=ifelse(Fire1418==1,"Fire","No_Fire")),
               method="glm", family="binomial",
               metric="ROC", trControl = ctrl)

cvFit

dplyr::select(cvFit$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
  geom_histogram(bins=35, fill = "#FF006A") +
  facet_wrap(~metric) +
  geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
       subtitle = "Across-fold mean reprented as dotted lines") +
  plotTheme()
```

### Spatial Cross Validation
To further test our model's generalizability, we conducted a spatial cross validation. By leaving out one county at a time, we were able to see how well our model predicts across space.

The maps below visualize predicted and actual fires for each of the 13 counties. They show that ADD SOMETHING HERE

```{r spatial_cv, message=FALSE, warning=FALSE, cache=TRUE}
# Model Validation
crossValidate <- function(dataset, id, dependentVariable, indVariables) {
  
  allPredictions <- data.frame()
  cvID_list <- unique(dataset[[id]])
  
  for (i in cvID_list) {
    
    thisFold <- i
    cat("This hold out fold is", thisFold, "\n")
    
    fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
      dplyr::select(id, geometry, indVariables, dependentVariable)
    fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
      dplyr::select(id, geometry, indVariables, dependentVariable)
    
    regression <-
      glm(Fire1418 ~ ., family = "binomial", 
          data = fold.train %>% 
            dplyr::select(-geometry, -id))
    
    thisPrediction <- 
      mutate(fold.test, Prediction = predict(regression, fold.test, type = "response"))
    
    allPredictions <-
      rbind(allPredictions, thisPrediction)
    
  }
  return(st_sf(allPredictions))
}

reg.vars <- c("FVEG_MAJ","ELEVATION_AV","SLOPE_MEAN", "COVER_MAJ","COUNTY_NAME",
              "MeanTemp1418","MeanHumidity1418","MeanWindSpeed1418",
              "n_fires_intersections","Conifer.nn","Hardwood.nn",
              "Facilities.nn","WUI.nn")


reg.spatialCV <- crossValidate(
  dataset = fishnet_clipped,
  id = "COUNTY_NAME",
  dependentVariable = "Fire1418",
  indVariables = reg.vars) 

reg.spatialcv <-
  reg.spatialCV %>%
  dplyr::select(cvID = COUNTY_NAME, Fire1418, Prediction, geometry)

ggplot() +
  geom_sf(data = reg.spatialcv, aes(fill = Prediction), color = "transparent")+
  geom_sf(data = fire_perimeter1418, fill = "transparent", color = "red")

reg.spatialcv <-
  reg.spatialcv %>%
  mutate(Error = Prediction - Fire1418)

ggplot() +
  geom_sf(data = reg.spatialcv, aes(fill = Error), color = "transparent")
```

# Discussion
Given the difficulty of predicting for rare events, and the notorious difficulty of forecasting wildfire behavior in particular, we are pleased with the performance of our model (Massey, 2013). Our cross validation indicates that the model is generalizable to new data and across the 13 counties. At a .2 threshold, which we feel is reasonable given the costs and benefits of overpredicting versus underpredicting fire, the model has high sensitivity and specificity.

While the model can predict fire over the course of several years with reasonable accuracy, it does not perform as well when predicting on a single year, as we saw when predicting for 2019 fires. This is likely because fire is a relatively rare event over the course of a single year, even though wildfires have become an increasing threat in California over recent years.

In building our model, we predicted fires in previous years based on historical weather data from the corresponding years. In order to predict future fire risk, we will need to incorporate accurate weather predictions into the model (Baraniuk, 2018). The model will need to be updated as climate change continues to impact weather patterns and wildfire occurances.

Rather than predicting whether or not fire will occur in a given grid cell, Spark Safe provides users with a risk score of Low, Medium, or High. This helps to address the issue of false negatives in our model, as homes with predicted fire probabilities below the .2 threshold but above 0 will be categorized under Medium Risk.

As we continue to refine the Spark Safe model, we hope to increase the sensitivity of the model while keeping the false negative rate reasonably low.

# Conclusion
NEED TO FIGURE OUT HOW TO ADD GEOMETRY BACK
```{r conclusion, warning=FALSE, message=FALSE}
# Map of Risk
## Need to add geometry! 
testProbs_all <- data.frame(Outcome = as.factor(fishnet_clipped$Fire1418),
                        Probs = predict(fireModel, fishnet_clipped, type= "response"),
                        ID= fishnet_clipped$ID)

testProbs_all <- testProbs_all %>% mutate(Risk_Cat=
                                            case_when(Probs <=.03 ~ "Low",
                                                   Probs > 0.03 & Probs < .2 ~ "Medium",
                                                   Probs >=.2 ~ "High" ))



fishnet_clipped_probs <- left_join(fishnet_clipped, testProbs_all, on = "ID")

palette3 <- c("#B81D13","#008450","#EFB700")

ggplot() +
  geom_sf(data=fishnet_clipped_probs, aes(fill=Risk_Cat), color="transparent")+
  scale_fill_manual(values=palette3, name="Risk Score") +
  labs(title="Predicted Risk Scores")+
  mapTheme()

```
**Sources**:
Baraniuk, C. (2018, October 7). The quest to predict - and stop - the spread of wildfires. *BBC*. https://www.bbc.com/future/article/20180924-the-quest-to-predict-and-stop-the-spread-of-wildfires
 
Massey, N. (2013, November 15). Finally, a Way to Predict a Wildfire's Behavior in Real Time. *Scientific American*. https://www.scientificamerican.com/article/finally-a-way-to-predict-a-wildfires-behavior-in-real-time/

Miller, R., Mach, K., & Field, C. (2020, October 29). Climate Change is Central to California's Wildfires. *Scientific American*. https://www.scientificamerican.com/article/climate-change-is-central-to-californias-wildfires/#:~:text=More%20than%20half%20of%20the,than%20doubled%20since%20the%201980s.&text=For%20wildfires%2C%20fuel%20treatments%20like,have%20become%20a%20salient%20example 

Public Resources Code. https://svfra.org/home/svfra/pdf/PRC%20429114%20and%20CA%20ADC%201299.pdf

Sommer, L. (2019, June 10). Who's Checking Your Neighborhood for Flammable Brush? Maybe No One. *KQED*. https://www.kqed.org/science/1943058/whos-checking-homes-for-flammable-brush-in-some-high-risk-areas-maybe-no-one

Yan, H., Mossburg, C., Moshtaghian, A., & Vercammen, P. (2020, September 6). California sets new record for land torched by wildfires as 224 people escape by air from a 'hellish' inferno. *CNN*. https://www.cnn.com/2020/09/05/us/california-mammoth-pool-reservoir-camp-fire/index.html 
